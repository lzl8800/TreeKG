# -*- coding: utf-8 -*-
"""
Dedup.py â€” Tree-KG Â§3.3.4 å®ä½“å»é‡ï¼ˆä¼˜åŒ–Â·å•æ–‡ä»¶è¾“å‡ºÂ·å«ä¸­æ–‡å‹å¥½åç§°ç›¸ä¼¼Â·è¯Šæ–­ï¼‰

æ€»ä½“æµç¨‹ï¼ˆè®ºæ–‡æ¡†æ¶ä¿ç•™ï¼‰ï¼š
  KNN(top-k, L2) â†’ è·ç¦»é˜ˆå€¼ + è§’è‰²è¿‡æ»¤ â†’ LLM åˆ¤å®šï¼ˆæŒ‰è·ç¦»å‡åºï¼‰ â†’ å¹¶æŸ¥é›†åˆå¹¶

å·¥ç¨‹ä¼˜åŒ–ï¼ˆé»˜è®¤å¼€å¯ï¼Œå…¼é¡¾å¬å›ä¸æˆæœ¬ï¼‰ï¼š
  - æ˜¾å¼å‘é‡ L2 å½’ä¸€åŒ–ï¼ˆé˜ˆå€¼è¯­ä¹‰ç¨³å®šï¼‰
  - äº’ä¸ºè¿‘é‚» mutual-kNNï¼ˆiâˆˆN(j) ä¸” jâˆˆN(i)ï¼‰
  - åŒè§’è‰²æ”¯æŒâ€œä¸¥æ ¼/å®½æ¾â€ä¸¤ç§æ¨¡å¼ï¼ˆé»˜è®¤å®½æ¾ï¼šä¸¤è¾¹éƒ½æœ‰ä¸”ä¸åŒæ‰è¿‡æ»¤ï¼‰
  - é™åˆ¶è¿‘é‚»æ’å rank_topï¼ˆé»˜è®¤å‰11åï¼š1..11ï¼‰
  - æ¯èŠ‚ç‚¹å€™é€‰é…é¢ per_node_capï¼ˆé»˜è®¤30ï¼‰
  - åç§° Jaccard è½»é‡è¿‡æ»¤ï¼ˆé»˜è®¤å¼€ï¼Œé˜ˆå€¼0.25ï¼›æ–°å¢ name_modeï¼štoken|char|bigram|autoï¼‰
  - â€œæ‹’ç»åŸå› è®¡æ•°å™¨â€è¯Šæ–­ï¼Œç²¾ç¡®çœ‹åˆ°å„è§„åˆ™çš„æŒ¡é‡

è¾“å‡ºï¼šä»… 1 ä¸ªæ–‡ä»¶ HiddenKG/output/dedup_result.json
"""

import os
import re
import json
import time
import pickle
import logging
import argparse
from typing import Dict, List, Tuple, Any
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

import numpy as np
from tqdm import tqdm

from pathlib import Path

# === å¯¼å…¥é…ç½®ï¼ˆæ ¸å¿ƒï¼šä» dedup_config è¯»å–æ‰€æœ‰å‚æ•°ï¼‰ ===
from HiddenKG.config import APIConfig
from HiddenKG.config import Dedup as DedupConfig

# åˆå§‹åŒ–è·¯å¾„ï¼ˆç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼‰
DedupConfig.ensure_paths()

# === å…¨å±€å˜é‡ä¸æ—¥å¿—é…ç½® ===
# æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger("Dedup")

# ä¼šè¯ä¿æŒï¼ˆå¤ç”¨è¿æ¥ï¼‰
SESSION = requests.Session()

# === å¯¼å…¥æŠ½ç¦»çš„æ¨¡å— ===
from Dedup.data_structures import Occurrence, Neighbor, EntityItem
from Dedup.knn import knn_topk
from Dedup.llm import llm_is_same, _fallback_is_same, _normalize_name
from Dedup.name_similarity import _name_jaccard_mode


# =========================
# I/O å·¥å…·å‡½æ•°
# =========================
def read_entities(infile: str) -> Dict[str, EntityItem]:
    """ä»JSONæ–‡ä»¶è¯»å–å®ä½“æ•°æ®å¹¶è½¬æ¢ä¸ºEntityItemå¯¹è±¡"""
    with open(infile, "r", encoding="utf-8") as f:
        raw = json.load(f)
    entities: Dict[str, EntityItem] = {}
    for name, d in raw.items():
        entities[name] = EntityItem(
            name=name,
            alias=d.get("alias", []),
            type=d.get("type", ""),
            original=d.get("original", ""),
            updated_description=d.get("updated_description", ""),
            role=d.get("role", d.get("local_role", "")),
            occurrences=[Occurrence(**o) for o in d.get("occurrences", [])],
            neighbors=[Neighbor(** n) for n in d.get("neighbors", [])],
        )
    logger.info(f"è½½å…¥å®ä½“ {len(entities)} ä¸ªï¼š{os.path.basename(infile)}")
    return entities


def read_embeddings(pkl_path: str) -> Tuple[List[str], np.ndarray]:
    """ä»PKLæ–‡ä»¶è¯»å–å®ä½“åµŒå…¥å‘é‡"""
    with open(pkl_path, "rb") as f:
        emb_dict = pickle.load(f)  # {name: np.ndarray(D,)}
    names = list(emb_dict.keys())
    embs = np.vstack([emb_dict[n] for n in names]).astype("float32")
    logger.info(f"è½½å…¥åµŒå…¥ {embs.shape[0]} x {embs.shape[1]}ï¼š{os.path.basename(pkl_path)}")
    return names, embs


# =========================
# å¹¶æŸ¥é›†æ•°æ®ç»“æ„ï¼ˆç”¨äºå®ä½“èšç±»ï¼‰
# =========================
class DSU:
    def __init__(self, n: int):
        self.fa = list(range(n))  # çˆ¶èŠ‚ç‚¹
        self.sz = [1] * n  # é›†åˆå¤§å°

    def find(self, x: int) -> int:
        """è·¯å¾„å‹ç¼©æŸ¥æ‰¾æ ¹èŠ‚ç‚¹"""
        while self.fa[x] != x:
            self.fa[x] = self.fa[self.fa[x]]  # å‹ç¼©è·¯å¾„
            x = self.fa[x]
        return x

    def union(self, a: int, b: int) -> bool:
        """æŒ‰å¤§å°åˆå¹¶ä¸¤ä¸ªé›†åˆ"""
        ra, rb = self.find(a), self.find(b)
        if ra == rb:
            return False  # å·²åœ¨åŒä¸€é›†åˆ
        # å°é›†åˆåˆå¹¶åˆ°å¤§è¿åˆ
        if self.sz[ra] < self.sz[rb]:
            ra, rb = rb, ra
        self.fa[rb] = ra
        self.sz[ra] += self.sz[rb]
        return True


# =========================
# ä¸»æµç¨‹å‡½æ•°
# =========================
def run_dedup(
    entities_in: str = None,
    emb_pkl: str = None,
    out_dir: str = str(DedupConfig.OUTPUT_DIR),
    # ä»é…ç½®æ–‡ä»¶è¯»å–é»˜è®¤å‚æ•°ï¼Œæ”¯æŒå¤–éƒ¨ä¼ å…¥è¦†ç›–
    k_neighbors: int = DedupConfig.KNN_NEIGHBORS,
    dist_thresh: float = DedupConfig.DIST_THRESHOLD,
    workers: int = DedupConfig.LLM_WORKERS,
    mutual_knn: bool = DedupConfig.MUTUAL_KNN,
    rank_top: int = DedupConfig.RANK_TOP,
    per_node_cap: int = DedupConfig.PER_NODE_CAP,
    strict_same_role: bool = DedupConfig.STRICT_SAME_ROLE,
    use_name_jaccard: bool = DedupConfig.USE_NAME_JACCARD,
    name_jaccard_min: float = DedupConfig.NAME_JACCARD_MIN,
    name_mode: str = DedupConfig.NAME_MODE,
    use_alias_fastpath: bool = DedupConfig.USE_ALIAS_FASTPATH,
    truncate_desc: bool = DedupConfig.TRUNCATE_DESC,
    desc_maxlen: int = DedupConfig.DESC_MAXLEN,
):
    t0 = time.time()
    os.makedirs(out_dir, exist_ok=True)

    # ---------------- 1. åŠ è½½å®ä½“ä¸åµŒå…¥æ–‡ä»¶ ----------------
    logger.info("ğŸ“˜ [1/5] åŠ è½½å®ä½“ä¸åµŒå…¥æ–‡ä»¶...")
    # è¾“å…¥å®ä½“è·¯å¾„ï¼ˆä¼˜å…ˆå¤–éƒ¨ä¼ å…¥ï¼Œå…¶æ¬¡é…ç½®æ–‡ä»¶é»˜è®¤ï¼‰
    ent_path = entities_in or str(DedupConfig.FILE_ENTITIES_IN)
    if not os.path.exists(ent_path):
        raise FileNotFoundError(f"å®ä½“æ–‡ä»¶ä¸å­˜åœ¨ï¼š{ent_path}")
    entities = read_entities(ent_path)

    # è¾“å…¥åµŒå…¥è·¯å¾„ï¼ˆä¼˜å…ˆå¤–éƒ¨ä¼ å…¥ï¼Œå…¶æ¬¡é…ç½®æ–‡ä»¶é»˜è®¤ï¼‰
    emb_path = emb_pkl or str(DedupConfig.FILE_EMBEDDINGS)
    if not os.path.exists(emb_path):
        raise FileNotFoundError(f"åµŒå…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼š{emb_path}")
    names_all, embs_all = read_embeddings(emb_path)
    name2idx = {n: i for i, n in enumerate(names_all)}

    # å¯¹é½å®ä½“ï¼ˆä»…ä¿ç•™å®ä½“æ–‡ä»¶å’ŒåµŒå…¥æ–‡ä»¶å…±æœ‰çš„å®ä½“ï¼‰
    names = [n for n in names_all if n in entities]
    if not names:
        raise ValueError("å®ä½“ä¸åµŒå…¥æ–‡ä»¶æ— äº¤é›†ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶")
    idx_keep = np.array([name2idx[n] for n in names], dtype=np.int64)
    embs = embs_all[idx_keep].astype("float32")

    # æ˜¾å¼L2å½’ä¸€åŒ–ï¼ˆç¡®ä¿è·ç¦»é˜ˆå€¼è¯­ä¹‰ç¨³å®šï¼‰
    embs /= (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-12)

    logger.info(f"âœ… å¯¹é½åå‚ä¸å»é‡çš„å®ä½“æ•°ï¼š{len(names)}")

    # ---------------- 2. è¿‘é‚»æ£€ç´¢ï¼ˆKNNï¼‰ ----------------
    logger.info("ğŸ“˜ [2/5] å¼€å§‹è¿‘é‚»æ£€ç´¢ï¼ˆFAISS/Sklearnï¼‰...")
    # æ£€ç´¢topk+1ï¼ˆå«è‡ªèº«ï¼‰
    dists, idxs = knn_topk(embs, topk=k_neighbors + 1)

    # æå–å®ä½“å±æ€§ç”¨äºè¿‡æ»¤
    ents: List[EntityItem] = [entities[n] for n in names]
    roles = [e.role or "" for e in ents]  # è§’è‰²åˆ—è¡¨
    dsu = DSU(len(names))  # åˆå§‹åŒ–å¹¶æŸ¥é›†

    # æ„å»ºäº’è¿‘é‚»è¡¨ï¼ˆæ¯ä¸ªå®ä½“çš„è¿‘é‚»é›†åˆï¼Œä¸å«è‡ªèº«ï¼‰
    N = len(names)
    nbr_sets = [set(idxs[i, 1:]) for i in range(N)]

    # ---------------- 3. å€™é€‰å¯¹è¿‡æ»¤ï¼ˆå¤šçº§è§„åˆ™ï¼‰ ----------------
    logger.info("ğŸ“˜ [3/5] æ”¶é›†å€™é€‰å¯¹ï¼ˆè·ç¦»é˜ˆå€¼ + è§’è‰² + åç§°Jaccard + äº’è¿‘é‚» + æ’å/é…é¢ï¼‰...")
    candidates: List[Tuple[int, int, float]] = []  # æœ€ç»ˆå€™é€‰å¯¹ (i, j, dist)
    cnt_pairs = 0  # åŸå§‹è¿‘é‚»å¯¹æ•°
    used = [0] * N  # è®°å½•æ¯ä¸ªå®ä½“å·²ä½¿ç”¨çš„å€™é€‰é…é¢

    # æ‹’ç»åŸå› è®¡æ•°å™¨ï¼ˆè¯Šæ–­ç”¨ï¼‰
    rej_dist = rej_role = rej_jac = rej_mutual = rej_cap = 0

    # é™åˆ¶è¿‘é‚»æ’åèŒƒå›´ï¼ˆè‡³å°‘å–å‰2åï¼‰
    rank_limit = max(2, int(rank_top))
    for i in range(N):
        # éå†å½“å‰å®ä½“çš„è¿‘é‚»ï¼ˆè·³è¿‡è‡ªèº«ï¼Œå–å‰rank_limit-1åï¼‰
        for rank in range(1, min(idxs.shape[1], rank_limit)):
            j = idxs[i, rank]
            if j <= i or j >= N:  # é¿å…é‡å¤å¯¹ï¼ˆi<jï¼‰å’Œè¶Šç•Œ
                continue
            cnt_pairs += 1
            dist = float(dists[i, rank])

            # 1. è·ç¦»é˜ˆå€¼è¿‡æ»¤
            if dist >= dist_thresh:
                rej_dist += 1
                continue

            # 2. è§’è‰²è¿‡æ»¤ï¼ˆä¸¥æ ¼/å®½æ¾æ¨¡å¼ï¼‰
            if strict_same_role:
                if roles[i] != roles[j]:
                    rej_role += 1
                    continue
            else:
                # å®½æ¾æ¨¡å¼ï¼šä¸¤è¾¹éƒ½æœ‰è§’è‰²ä¸”ä¸åŒæ‰è¿‡æ»¤
                if roles[i] and roles[j] and roles[i] != roles[j]:
                    rej_role += 1
                    continue

            # 3. åç§°Jaccardç›¸ä¼¼åº¦è¿‡æ»¤
            if use_name_jaccard:
                jac_sim = _name_jaccard_mode(ents[i].name, ents[j].name, name_mode)
                if jac_sim < name_jaccard_min:
                    rej_jac += 1
                    continue

            # 4. äº’è¿‘é‚»è¿‡æ»¤
            if mutual_knn and (i not in nbr_sets[j]):
                rej_mutual += 1
                continue

            # 5. æ¯èŠ‚ç‚¹å€™é€‰é…é¢è¿‡æ»¤
            if per_node_cap > 0 and (used[i] >= per_node_cap or used[j] >= per_node_cap):
                rej_cap += 1
                continue

            # æ‰€æœ‰è¿‡æ»¤é€šè¿‡ï¼ŒåŠ å…¥å€™é€‰å¯¹
            candidates.append((i, j, dist))
            used[i] += 1
            used[j] += 1

    # è¾“å‡ºè¿‡æ»¤è¯Šæ–­ä¿¡æ¯
    logger.info(f"ğŸ“Œ å€™é€‰å¯¹ï¼ˆé€šè¿‡åˆç­›ï¼‰ï¼š{len(candidates)} / åŸå§‹å¯¹æ•°ï¼š{cnt_pairs}")
    logger.info(f"[è¯Šæ–­] è¿‡æ»¤ç»Ÿè®¡: è·ç¦»={rej_dist} è§’è‰²={rej_role} åç§°Jaccard={rej_jac} äº’è¿‘é‚»={rej_mutual} é…é¢={rej_cap}")
    # è¾“å‡ºè·ç¦»åˆ†ä½æ•°ï¼ˆè¾…åŠ©è°ƒæ•´é˜ˆå€¼ï¼‰
    if candidates:
        kept_d = np.array([d for (_, _, d) in candidates], dtype=np.float32)
        qs = np.percentile(kept_d, [5, 10, 25, 50, 75, 90, 95])
        logger.info(f"[è¯Šæ–­] åˆç­›è·ç¦»åˆ†ä½æ•° p5..p95: {np.round(qs, 4)}")

    # ---------------- 3.5 å¯é€‰ï¼šåˆ«åäº¤é›†å¿«é€Ÿåˆå¹¶ ----------------
    rep_fast_merge = 0
    kept_for_llm: List[Tuple[int, int, float]] = candidates
    if use_alias_fastpath:
        logger.info("ğŸ“˜ [3.5] å¿«é€Ÿé€šé“ï¼šåˆ«å/åç§°äº¤é›†ç›´æ¥åˆå¹¶ï¼ˆå¯é€‰ï¼‰...")
        def alias_intersect(a: EntityItem, b: EntityItem) -> bool:
            """æ£€æŸ¥ä¸¤ä¸ªå®ä½“çš„åç§°/åˆ«åæ˜¯å¦æœ‰äº¤é›†"""
            alias_a = {_normalize_name(x) for x in ([a.name] + a.alias)}
            alias_b = {_normalize_name(x) for x in ([b.name] + b.alias)}
            return len(alias_a & alias_b) > 0

        tmp_kept: List[Tuple[int, int, float]] = []
        for (i, j, dist) in candidates:
            if alias_intersect(ents[i], ents[j]):
                if dsu.union(i, j):
                    rep_fast_merge += 1
            else:
                tmp_kept.append((i, j, dist))
        kept_for_llm = tmp_kept
        logger.info(f"âœ… å¿«é€Ÿåˆå¹¶å®Œæˆï¼š{rep_fast_merge} æ¡ï¼›è¿›å…¥ LLM çš„å¯¹æ•°ï¼š{len(kept_for_llm)}")
    else:
        logger.info(f"ğŸ“˜ [3.5] è·³è¿‡å¿«é€Ÿé€šé“ï¼›è¿›å…¥ LLM çš„å¯¹æ•°ï¼š{len(kept_for_llm)}")

    # ---------------- 4. LLM å¹¶è¡Œåˆ¤å®š ----------------
    logger.info(f"ğŸ“˜ [4/5] LLM å¹¶è¡Œåˆ¤å®šï¼ˆå¹¶å‘={workers}ï¼›æŒ‰è·ç¦»å‡åºï¼‰...")
    # æŒ‰è·ç¦»å‡åºæ’åºï¼ˆä¼˜å…ˆå¤„ç†æ›´å¯èƒ½ç›¸ä¼¼çš„å¯¹ï¼‰
    kept_for_llm.sort(key=lambda x: x[2])
    llm_cache: Dict[Tuple[str, str], Tuple[bool, str]] = {}  # ç¼“å­˜LLMç»“æœé¿å…é‡å¤è°ƒç”¨
    cnt_llm_calls = 0  # å®é™…LLMè°ƒç”¨æ¬¡æ•°
    cnt_fallback = 0  # å…œåº•é€»è¾‘è°ƒç”¨æ¬¡æ•°
    cnt_merged = rep_fast_merge  # åˆå¹¶æ€»æ•°ï¼ˆåˆå§‹ä¸ºå¿«é€Ÿåˆå¹¶æ•°ï¼‰
    merge_decisions: List[Tuple[str, str, bool, float, str]] = []  # åˆ¤å®šè®°å½•

    def judge_pair(i: int, j: int, dist: float) -> Tuple[int, int, bool, float, str, bool]:
        """å•å¯¹å®ä½“åˆ¤å®šï¼ˆå°è£…ä¸ºçº¿ç¨‹ä»»åŠ¡ï¼‰"""
        ent_i, ent_j = ents[i], ents[j]
        # ç”Ÿæˆç¼“å­˜é”®ï¼ˆæ’åºç¡®ä¿(a,b)å’Œ(b,a)ä¸ºåŒä¸€é”®ï¼‰
        key = tuple(sorted((ent_i.name, ent_j.name)))
        if key in llm_cache:
            # å‘½ä¸­ç¼“å­˜
            is_same, reason = llm_cache[key]
            return (i, j, is_same, dist, reason, False)
        else:
            # è°ƒç”¨LLMåˆ¤å®š
            is_same, reason, used_fallback = llm_is_same(
                ent_i, ent_j,
                truncate_desc=truncate_desc,
                desc_maxlen=desc_maxlen
            )
            llm_cache[key] = (is_same, reason)
            return (i, j, is_same, dist, reason, used_fallback)

    # å¹¶è¡Œæ‰§è¡ŒLLMåˆ¤å®š
    with ThreadPoolExecutor(max_workers=max(1, int(workers))) as ex:
        futures = [ex.submit(judge_pair, i, j, dist) for (i, j, dist) in kept_for_llm]
        for fut in tqdm(as_completed(futures), total=len(futures), desc="LLMåˆ¤å®šä¸­", ncols=80):
            i, j, is_same, dist, reason, used_fallback = fut.result()
            # æ›´æ–°ç»Ÿè®¡
            if used_fallback:
                cnt_fallback += 1
            else:
                cnt_llm_calls += 1
            # è®°å½•åˆ¤å®šç»“æœ
            merge_decisions.append((ents[i].name, ents[j].name, is_same, dist, reason))
            # åˆå¹¶å®ä½“ï¼ˆå¹¶æŸ¥é›†ï¼‰
            if is_same and dsu.union(i, j):
                cnt_merged += 1

    # ---------------- 5. æ„å»ºç­‰ä»·ç±»å¹¶åˆå¹¶å®ä½“ ----------------
    logger.info("ğŸ“˜ [5/5] æ„å»ºç­‰ä»·ç±»ã€åˆå¹¶å¹¶å†™å‡ºå•ä¸€ç»“æœæ–‡ä»¶...")
    # æ„å»ºèšç±»ï¼ˆç­‰ä»·ç±»ï¼‰
    clusters: Dict[int, List[int]] = {}
    for x in range(len(names)):
        root = dsu.find(x)
        clusters.setdefault(root, []).append(x)

    # è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—æè¿°é•¿åº¦ï¼ˆç”¨äºé€‰æ‹©ä»£è¡¨å®ä½“ï¼‰
    def desc_len(e: EntityItem) -> int:
        return len((e.updated_description or e.original or "").strip())

    # è¾…åŠ©å‡½æ•°ï¼šåˆå¹¶ä¸¤ä¸ªå®ä½“ï¼ˆä¿ç•™æ›´å®Œæ•´çš„ä¿¡æ¯ï¼‰
    def merge_two(base: EntityItem, other: EntityItem) -> None:
        # åˆå¹¶åˆ«åï¼ˆå»é‡ï¼Œæ’é™¤è‡ªèº«åç§°ï¼‰
        merged_alias = list(dict.fromkeys(base.alias + other.alias + [other.name]))
        base.alias = [a for a in merged_alias if a != base.name]

        # åˆå¹¶å‡ºç°ä½ç½®ï¼ˆå»é‡ï¼‰
        occ_seen = {(o.path, o.node_id) for o in base.occurrences}
        for o in other.occurrences:
            key = (o.path, o.node_id)
            if key not in occ_seen:
                base.occurrences.append(o)
                occ_seen.add(key)

        # åˆå¹¶é‚»å±…ï¼ˆå»é‡ï¼Œæ’é™¤è‡ªç¯ï¼‰
        nb_seen = {(n.name, n.snippet) for n in base.neighbors}
        for n in other.neighbors:
            if n.name == base.name:
                continue  # è·³è¿‡è‡ªç¯
            key = (n.name, n.snippet)
            if key not in nb_seen:
                base.neighbors.append(n)
                nb_seen.add(key)

        # æ‹©ä¼˜ä¿ç•™æè¿°ï¼ˆå–æ›´é•¿çš„ï¼‰
        if desc_len(other) > desc_len(base):
            base.updated_description = other.updated_description or other.original

    # ç”Ÿæˆåˆå¹¶æ˜ å°„ä¸æœ€ç»ˆå®ä½“
    rep_map: Dict[str, str] = {}  # å­å®ä½“â†’ä¸»å®ä½“æ˜ å°„
    new_entities: Dict[str, EntityItem] = {}

    for root, members in clusters.items():
        if len(members) == 1:
            # å•å®ä½“èšç±»ï¼Œç›´æ¥ä¿ç•™
            e = ents[members[0]]
            new_entities[e.name] = e
            continue
        # æŒ‰æè¿°é•¿åº¦æ’åºï¼Œé€‰æœ€é•¿æè¿°çš„å®ä½“ä½œä¸ºä»£è¡¨
        members_sorted = sorted(members, key=lambda idx: desc_len(ents[idx]), reverse=True)
        rep_idx = members_sorted[0]
        rep = ents[rep_idx]
        rep_name = rep.name
        # åˆå¹¶å…¶ä»–å®ä½“åˆ°ä»£è¡¨å®ä½“
        for idx in members_sorted[1:]:
            child = ents[idx]
            if child.name == rep_name:
                continue
            merge_two(rep, child)
            rep_map[child.name] = rep_name
        new_entities[rep_name] = rep

    # é‚»å±…é‡å®šå‘ï¼ˆæ›´æ–°ä¸ºåˆå¹¶åçš„å®ä½“åç§°ï¼‰
    redirect = rep_map.copy()
    for parent_ent in new_entities.values():
        new_neighbors: List[Neighbor] = []
        seen = set()
        for nb in parent_ent.neighbors:
            # é‡å®šå‘é‚»å±…åç§°
            tgt = redirect.get(nb.name, nb.name)
            if tgt == parent_ent.name:
                continue  # è·³è¿‡è‡ªç¯
            key = (tgt, nb.snippet)
            if key in seen:
                continue  # å»é‡
            seen.add(key)
            new_neighbors.append(Neighbor(name=tgt, snippet=nb.snippet))
        parent_ent.neighbors = new_neighbors

    # ---------------- è¾“å‡ºç»“æœ ----------------
    # æ•´ç†è¾“å‡ºæ•°æ®
    out_entities = {
        e.name: {
            "name": e.name,
            "alias": e.alias,
            "type": e.type,
            "original": e.original,
            "updated_description": e.updated_description,
            "role": e.role,
            "occurrences": [o.__dict__ for o in e.occurrences],
            "neighbors": [n.__dict__ for n in e.neighbors],
        }
        for e in new_entities.values()
    }
    # èšç±»åç§°åˆ—è¡¨
    clusters_names = [[names[i] for i in members] for members in clusters.values()]
    # åˆ¤å®šè®°å½•åˆ—è¡¨
    decisions_list = [
        {
            "a": a_name,
            "b": b_name,
            "is_same": same,
            "dist": round(float(dist), 6),
            "reason": reason
        }
        for a_name, b_name, same, dist, reason in merge_decisions
    ]

    # æ±‡æ€»å…ƒæ•°æ®ä¸ç»Ÿè®¡ä¿¡æ¯
    t1 = time.time()
    result = {
        "meta": {
            "entities_in": os.path.abspath(ent_path),
            "emb_pkl": os.path.abspath(emb_path),
            "k_neighbors": k_neighbors,
            "dist_thresh": dist_thresh,
            "workers": workers,
            "mutual_knn": mutual_knn,
            "rank_top": rank_top,
            "per_node_cap": per_node_cap,
            "strict_same_role": strict_same_role,
            "use_name_jaccard": use_name_jaccard,
            "name_jaccard_min": name_jaccard_min,
            "name_mode": name_mode,
            "use_alias_fastpath": use_alias_fastpath,
            "truncate_desc": truncate_desc,
            "desc_maxlen": desc_maxlen,
            "api_model": getattr(APIConfig, "MODEL_NAME", "unknown"),
            "api_timeout": DedupConfig.API_TIMEOUT,
            "api_retries": DedupConfig.RETRIES,
            "duration_sec": round(t1 - t0, 2),
        },
        "summary": {
            "pairs_raw": cnt_pairs,
            "pairs_after_filter": len(candidates),
            "pairs_to_llm": len(kept_for_llm),
            "llm_calls": cnt_llm_calls,
            "fallback_calls": cnt_fallback,
            "merged_edges": cnt_merged,
            "entities_before": len(entities),
            "entities_after": len(new_entities),
        },
        "entities": out_entities,
        "clusters": clusters_names,
        "merge_map": rep_map,
        "decisions": decisions_list,
    }

    # å†™å…¥è¾“å‡ºæ–‡ä»¶
    out_path = os.path.join(out_dir, "dedup_result.json")
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    # è¾“å‡ºè¿è¡Œæ‘˜è¦
    logger.info("\nâ€”â€” å»é‡ä»»åŠ¡æ‘˜è¦ â€”â€”")
    logger.info(f"å€™é€‰å¯¹åŸå§‹æ•°é‡ï¼š{cnt_pairs}")
    logger.info(f"è¿›å…¥ LLM åˆ¤å®šçš„æ•°é‡ï¼š{len(kept_for_llm)}ï¼ˆå·²å¹¶è¡Œå¤„ç†ï¼‰")
    logger.info(f"LLM è°ƒç”¨ï¼š{cnt_llm_calls} æ¬¡ï¼ˆfallbackï¼š{cnt_fallback} æ¬¡ï¼‰")
    logger.info(f"æˆåŠŸåˆå¹¶çš„å®ä½“å¯¹ï¼š{cnt_merged}")
    logger.info(f"å®ä½“æ•°é‡å˜åŒ–ï¼š{len(entities)} -> {len(new_entities)}")
    logger.info(f"æ€»è€—æ—¶ï¼š{t1 - t0:.2f} ç§’")
    logger.info(f"ç»“æœæ–‡ä»¶ï¼š{os.path.abspath(out_path)}")


# =========================
# å‘½ä»¤è¡Œæ¥å£ï¼ˆCLIï¼‰
# =========================
def main():
    parser = argparse.ArgumentParser(description="Tree-KG å®ä½“å»é‡ï¼ˆä¼˜åŒ–Â·å•æ–‡ä»¶è¾“å‡ºÂ·ä¸­æ–‡å‹å¥½åç§°ç›¸ä¼¼Â·å«è¯Šæ–­ï¼‰")
    # è¾“å…¥è¾“å‡ºè·¯å¾„
    parser.add_argument("--entities", type=str, default="", help=f"å®ä½“JSONè·¯å¾„ï¼ˆé»˜è®¤ï¼š{DedupConfig.FILE_ENTITIES_IN}ï¼‰")
    parser.add_argument("--emb", type=str, default="", help=f"åµŒå…¥PKLè·¯å¾„ï¼ˆé»˜è®¤ï¼š{DedupConfig.FILE_EMBEDDINGS}ï¼‰")
    parser.add_argument("--out", type=str, default=str(DedupConfig.OUTPUT_DIR), help=f"è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼š{DedupConfig.OUTPUT_DIR}ï¼‰")

    # KNNå‚æ•°
    parser.add_argument("--k", type=int, default=DedupConfig.KNN_NEIGHBORS, help=f"KNNè¿‘é‚»ä¸ªæ•°ï¼ˆé»˜è®¤ï¼š{DedupConfig.KNN_NEIGHBORS}ï¼‰")
    parser.add_argument("--th", type=float, default=DedupConfig.DIST_THRESHOLD, help=f"L2è·ç¦»é˜ˆå€¼ï¼ˆé»˜è®¤ï¼š{DedupConfig.DIST_THRESHOLD}ï¼‰")

    # å¹¶å‘ä¸LLMå‚æ•°
    parser.add_argument("--workers", type=int, default=DedupConfig.LLM_WORKERS, help=f"LLMå¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š{DedupConfig.LLM_WORKERS}ï¼‰")

    # ä¼˜åŒ–å¼€å…³
    parser.add_argument("--mutual_knn", dest="mutual_knn", action="store_true", help=f"å¯ç”¨äº’ä¸ºè¿‘é‚»ï¼ˆé»˜è®¤ï¼š{DedupConfig.MUTUAL_KNN}ï¼‰")
    parser.add_argument("--no_mutual_knn", dest="mutual_knn", action="store_false")
    parser.set_defaults(mutual_knn=DedupConfig.MUTUAL_KNN)

    parser.add_argument("--rank_top", type=int, default=DedupConfig.RANK_TOP, help=f"è¿‘é‚»æ’åä¸Šé™ï¼ˆé»˜è®¤ï¼š{DedupConfig.RANK_TOP}ï¼‰")
    parser.add_argument("--per_node_cap", type=int, default=DedupConfig.PER_NODE_CAP, help=f"æ¯èŠ‚ç‚¹å€™é€‰é…é¢ï¼ˆé»˜è®¤ï¼š{DedupConfig.PER_NODE_CAP}ï¼‰")

    parser.add_argument("--strict_same_role", dest="strict_same_role", action="store_true", help=f"ä¸¥æ ¼è§’è‰²åŒ¹é…ï¼ˆé»˜è®¤ï¼š{DedupConfig.STRICT_SAME_ROLE}ï¼‰")
    parser.add_argument("--no_strict_same_role", dest="strict_same_role", action="store_false")
    parser.set_defaults(strict_same_role=DedupConfig.STRICT_SAME_ROLE)

    parser.add_argument("--use_name_jaccard", dest="use_name_jaccard", action="store_true", help=f"å¯ç”¨åç§°Jaccardè¿‡æ»¤ï¼ˆé»˜è®¤ï¼š{DedupConfig.USE_NAME_JACCARD}ï¼‰")
    parser.add_argument("--no_use_name_jaccard", dest="use_name_jaccard", action="store_false")
    parser.set_defaults(use_name_jaccard=DedupConfig.USE_NAME_JACCARD)

    parser.add_argument("--name_jaccard_min", type=float, default=DedupConfig.NAME_JACCARD_MIN, help=f"åç§°Jaccardé˜ˆå€¼ï¼ˆé»˜è®¤ï¼š{DedupConfig.NAME_JACCARD_MIN}ï¼‰")
    parser.add_argument("--name_mode", type=str, default=DedupConfig.NAME_MODE, choices=["token", "char", "bigram", "auto"], help=f"åç§°ç›¸ä¼¼åº¦æ¨¡å¼ï¼ˆé»˜è®¤ï¼š{DedupConfig.NAME_MODE}ï¼‰")

    parser.add_argument("--use_alias_fastpath", action="store_true", default=DedupConfig.USE_ALIAS_FASTPATH, help=f"å¯ç”¨åˆ«åå¿«é€Ÿåˆå¹¶ï¼ˆé»˜è®¤ï¼š{DedupConfig.USE_ALIAS_FASTPATH}ï¼‰")
    parser.add_argument("--truncate_desc", action="store_true", default=DedupConfig.TRUNCATE_DESC, help=f"å¯ç”¨æè¿°æˆªæ–­ï¼ˆé»˜è®¤ï¼š{DedupConfig.TRUNCATE_DESC}ï¼‰")
    parser.add_argument("--desc_maxlen", type=int, default=DedupConfig.DESC_MAXLEN, help=f"æè¿°æˆªæ–­é•¿åº¦ï¼ˆé»˜è®¤ï¼š{DedupConfig.DESC_MAXLEN}ï¼‰")

    args = parser.parse_args()

    # æ‰§è¡Œå»é‡ä»»åŠ¡
    run_dedup(
        entities_in=args.entities or None,
        emb_pkl=args.emb or None,
        out_dir=args.out,
        k_neighbors=args.k,
        dist_thresh=args.th,
        workers=args.workers,
        mutual_knn=args.mutual_knn,
        rank_top=args.rank_top,
        per_node_cap=args.per_node_cap,
        strict_same_role=args.strict_same_role,
        use_name_jaccard=args.use_name_jaccard,
        name_jaccard_min=args.name_jaccard_min,
        name_mode=args.name_mode,
        use_alias_fastpath=args.use_alias_fastpath,
        truncate_desc=args.truncate_desc,
        desc_maxlen=args.desc_maxlen,
    )


if __name__ == "__main__":
    main()