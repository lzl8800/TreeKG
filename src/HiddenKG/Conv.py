# -*- coding: utf-8 -*-
"""
HiddenKG ç¬¬ä¸€æ­¥ï¼šContextual-based Convolutionï¼ˆconvï¼‰

è¾“å‡ºï¼š
  - HiddenKG/output/conv_entities.json

æ—¥å¿—ï¼š
  - HiddenKG/logs/conv.log  ï¼ˆè¯¦ç»†ï¼‰
  - ç»ˆç«¯ï¼šä»…å¿…è¦ä¿¡æ¯ + è¿›åº¦æ¡

ä¾èµ–ï¼š
  - HiddenKG/config/config.yamlï¼ˆé€šè¿‡ include_files å¼•å…¥ config/conv.yamlï¼‰
  - éœ€è¦ config å†…å«:
      APIConfig: { API_BASE, API_KEY, MODEL_NAME, TIMEOUT_SECS(å¯é€‰) }
      ConvConfig: è§ conv.yaml
"""

from __future__ import annotations

import json
import time
import logging
import requests
import re
import os
import threading
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Dict, List, Tuple, Any, DefaultDict, Optional
from collections import defaultdict
import yaml
from tqdm import tqdm
import sys

# ========== é…ç½®åŠ è½½ ==========
def load_config(config_file: Path) -> dict:
    with config_file.open("r", encoding="utf-8") as f:
        base = yaml.safe_load(f) or {}
    if "include_files" in base:
        merged = dict(base)
        for rel in base["include_files"]:
            inc_path = (config_file.parent / rel).resolve()
            with inc_path.open("r", encoding="utf-8") as ff:
                part = yaml.safe_load(ff) or {}
            merged.update(part)
        return merged
    return base

# å½“å‰æ¨¡å—ç›®å½•ï¼šsrc/HiddenKG
script_dir = Path(__file__).resolve().parent
config_file = script_dir / "config" / "config.yaml"
config = load_config(config_file)

APIConfig = config.get("APIConfig", {})
ConvConfig = config.get("ConvConfig", {})

# ç›®å½•
hidden_dir = script_dir                                 # src/HiddenKG
explicit_dir = script_dir.parent / "ExplicitKG"         # src/ExplicitKG
hidden_output_dir = hidden_dir / "output"
hidden_logs_dir = hidden_dir / "logs"
explicit_output_dir = explicit_dir / "output"
hidden_output_dir.mkdir(parents=True, exist_ok=True)
hidden_logs_dir.mkdir(parents=True, exist_ok=True)

# æ–‡ä»¶è·¯å¾„
FILE_TOC_ENT_REL = explicit_output_dir / ConvConfig.get("TOC_ENT_REL_NAME", "toc_with_entities_and_relations.json")
FILE_CONV_RESULT = hidden_output_dir / ConvConfig.get("CONV_RESULT_NAME", "conv_entities.json")
FILE_CONV_PROMPTS = hidden_output_dir / ConvConfig.get("CONV_PROMPTS_NAME", "conv_prompts.json")  # è‹¥åŽç»­éœ€è¦å¯å†™

# è¿è¡Œå‚æ•°
TEMPERATURE = float(ConvConfig.get("TEMPERATURE", 0.2))
MAX_TOKENS = int(ConvConfig.get("MAX_TOKENS", 300))
API_TIMEOUT = int(ConvConfig.get("API_TIMEOUT", 120))
RETRIES = int(ConvConfig.get("RETRIES", 3))
CHAT_COMPLETIONS_PATH = ConvConfig.get("CHAT_COMPLETIONS_PATH", "/chat/completions")
RATE_LIMIT_QPS = float(ConvConfig.get("RATE_LIMIT_QPS", 0))
EXTRA_THROTTLE_SEC = float(ConvConfig.get("EXTRA_THROTTLE_SEC", 0.0))
RETRY_BACKOFF_BASE = float(ConvConfig.get("RETRY_BACKOFF_BASE", 1.8))
MAX_NEIGHBORS_GLOBAL = int(ConvConfig.get("MAX_NEIGHBORS_GLOBAL", 30))
DRY_RUN = bool(ConvConfig.get("DRY_RUN", False))

# ========== æ—¥å¿— ==========
LOG_PATH = hidden_logs_dir / "conv.log"
# æ–‡ä»¶æ—¥å¿—ï¼šINFO çº§åˆ«ï¼ˆè¯¦ç»†ï¼‰
file_handler = logging.FileHandler(LOG_PATH, encoding="utf-8")
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s"))

# æŽ§åˆ¶å°æ—¥å¿—ï¼šWARNINGï¼ˆä»…å¿…è¦ä¿¡æ¯ï¼›è¿›åº¦æ¡ç”± tqdm è´Ÿè´£ï¼‰
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.WARNING)
console_handler.setFormatter(logging.Formatter("[%(levelname)s] %(message)s"))

logger = logging.getLogger("Conv")
logger.setLevel(logging.INFO)
# é˜²æ­¢é‡å¤æ·»åŠ 
if not logger.handlers:
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
else:
    logger.handlers.clear()
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

# ========== æ•°æ®ç»“æž„ ==========
@dataclass
class Occurrence:
    path: str
    node_id: str
    level: int
    title: str

@dataclass
class Neighbor:
    name: str
    snippet: str = ""  # å…³ç³»æè¿°ï¼ˆåŒå°èŠ‚æ‘˜è¦æˆ–çŸ­æ–‡æœ¬ï¼‰

@dataclass
class EntityItem:
    name: str
    alias: List[str]
    type: str
    original: str
    occurrences: List[Occurrence]
    neighbors: List[Neighbor]
    updated_description: str = ""

# ========== TOC éåŽ†ä¸Žå®žä½“è¯»å– ==========
def _iter_toc_nodes(toc: List[Dict[str, Any]], parent_path=""):
    for node in toc:
        title = node.get("title", "")
        node_id = node.get("id", "")
        level = node.get("level", -1)
        path = f"{parent_path} > {title}" if parent_path else title
        yield node, path, node_id, level
        for child in node.get("children", []) or []:
            yield from _iter_toc_nodes([child], path)

def load_entities_from_toc(file_path: Path) -> Dict[str, EntityItem]:
    """
    ä»…ä»Ž TOC è¯»å–å®žä½“ä¸Žâ€œåŒå°èŠ‚å…±çŽ°é‚»å±…â€ã€‚
    """
    with file_path.open("r", encoding="utf-8") as f:
        toc = json.load(f)

    entities: Dict[str, EntityItem] = {}
    leaf_entities: Dict[str, List[Tuple[str, str]]] = {}

    for node, path, node_id, level in _iter_toc_nodes(toc):
        ents = node.get("entities") or []
        if not ents:
            continue
        for e in ents:
            name = (e.get("name") or "").strip()
            if not name:
                continue
            original = (e.get("raw_content") or "").strip()
            alias = e.get("alias") or []
            etype = e.get("type") or ""
            if name not in entities:
                entities[name] = EntityItem(name, alias, etype, original, [], [])
            entities[name].occurrences.append(Occurrence(path, node_id, level, node.get("title", "")))
            leaf_entities.setdefault(node_id, []).append((name, original))

    # é‚»å±…ï¼šåŒå°èŠ‚å…±çŽ°
    for node_id, name_list in leaf_entities.items():
        for name, _ in name_list:
            neighbor_map = {n.name: n for n in entities[name].neighbors}
            for n_name, n_snip in name_list:
                if n_name == name:
                    continue
                neighbor_map.setdefault(n_name, Neighbor(n_name, (n_snip or "")[:100]))
            # é™é¢
            entities[name].neighbors = list(neighbor_map.values())[:MAX_NEIGHBORS_GLOBAL]

    logger.info(f"[TOC] åŠ è½½å®žä½“ {len(entities)} ä¸ªï¼›æ¥è‡ªæ–‡ä»¶ï¼š{file_path}")
    return entities

# ========== Prompt ==========
def build_system_prompt() -> str:
    return (
        "ä½ æ˜¯â€œMATLABç§‘å­¦è®¡ç®—è¯¾ç¨‹çŸ¥è¯†å›¾è°±ä¸“å®¶â€ã€‚"
        "è¯·åŸºäºŽé‚»åŸŸå…³ç³»å¢žå¼ºå®žä½“æè¿°ï¼Œä¿æŒæœ¯è¯­å‡†ç¡®ï¼Œä¸­æ–‡è¾“å‡ºï¼Œ200â€“300å­—ä»¥å†…ã€‚"
    )

def build_user_prompt(entity: EntityItem) -> str:
    neighbor_lines = []
    for nb in entity.neighbors:
        snip = (nb.snippet or "").replace("\n", " ").strip()
        neighbor_lines.append(f"- {nb.name}ï¼š{snip}" if snip else f"- {nb.name}")
    occ_str = "; ".join([o.path for o in entity.occurrences[:3]])
    return (
        f"ç›®æ ‡å®žä½“ï¼š{entity.name}\n"
        f"åŽŸå§‹æè¿°ï¼š{entity.original or 'ï¼ˆæ— æè¿°ï¼‰'}\n"
        f"å‡ºçŽ°ä½ç½®ï¼š{occ_str or 'ï¼ˆæ— ï¼‰'}\n"
        f"é‚»åŸŸå®žä½“ï¼š\n" + "\n".join(neighbor_lines) + "\n"
        "ä»»åŠ¡ï¼šåŸºäºŽä¸Šä¸‹æ–‡ç”Ÿæˆå¢žå¼ºæè¿°ï¼Œèšç„¦å…¶å®šä¹‰ã€ä½œç”¨åŠä¸Žé‚»åŸŸçš„å…³ç³»ã€‚\n"
        "è¯·è¿”å›žJSONï¼š{\"name\": \"å®žä½“å\", \"updated_description\": \"å¢žå¼ºåŽçš„æè¿°\"}"
    )

# ========== é™é€Ÿ ==========
_rate_lock = threading.Lock()
_last_ts = 0.0
_min_interval = (1.0 / RATE_LIMIT_QPS) if RATE_LIMIT_QPS > 0 else 0.0

def _rate_limit_block():
    if _min_interval <= 0:
        return
    global _last_ts
    with _rate_lock:
        now = time.time()
        delta = now - _last_ts
        if delta < _min_interval:
            time.sleep(_min_interval - delta)
        _last_ts = time.time()

# ========== LLM è°ƒç”¨ ==========
def call_llm(system_prompt: str, user_prompt: str) -> str:
    """è°ƒç”¨ OpenAI å…¼å®¹ /chat/completionsï¼›æ”¯æŒæ— é‰´æƒæœ¬åœ°ç½‘å…³"""
    if DRY_RUN:
        return ""

    api_base = APIConfig.get("API_BASE", "")
    if not api_base:
        logger.warning("API_BASE ä¸ºç©ºï¼Œè·³è¿‡ LLM è°ƒç”¨ã€‚")
        return ""

    headers = {"Content-Type": "application/json"}
    api_key = APIConfig.get("API_KEY")
    if api_key:
        headers["Authorization"] = f"Bearer {api_key}"

    payload = {
        "model": APIConfig.get("MODEL_NAME", ""),
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": TEMPERATURE,
        "max_tokens": MAX_TOKENS
    }

    last_err: Optional[Exception] = None
    for k in range(RETRIES):
        try:
            _rate_limit_block()
            if EXTRA_THROTTLE_SEC > 0:
                time.sleep(EXTRA_THROTTLE_SEC)

            resp = requests.post(
                f"{api_base}{CHAT_COMPLETIONS_PATH}",
                headers=headers,
                json=payload,
                timeout=API_TIMEOUT
            )
            resp.raise_for_status()
            return resp.json()["choices"][0]["message"]["content"].strip()
        except Exception as e:
            last_err = e
            logger.warning(f"LLM è°ƒç”¨å¤±è´¥({k+1}/{RETRIES})ï¼š{e}")
            time.sleep(RETRY_BACKOFF_BASE ** k)
    logger.error(f"LLM è¯·æ±‚å¤±è´¥ï¼š{last_err}")
    return ""

# ========== è§£æžä¸Žæ¸…æ´— ==========
def safe_json_loads(txt: str) -> Dict[str, Any]:
    if not txt or not isinstance(txt, str):
        return {}
    txt = txt.strip()
    try:
        return json.loads(txt)
    except Exception:
        pass
    candidates = re.findall(r"\{[^{}]*\}", txt)
    for c in candidates:
        try:
            obj = json.loads(c)
            if isinstance(obj, dict) and "name" in obj:
                return obj
        except Exception:
            continue
    start, end = txt.find("{"), txt.rfind("}")
    if start != -1 and end != -1 and end > start:
        segment = txt[start:end + 1]
        try:
            return json.loads(segment)
        except Exception:
            cleaned = re.sub(r"^[^{]*|[^}]*$", "", segment)
            try:
                return json.loads(cleaned)
            except Exception:
                return {}
    return {}

def _enforce_len_200_300(s: str) -> str:
    s = (s or "").replace("\n", " ").strip()
    if len(s) > 300:
        s = s[:300]
        for c in "ã€‚ï¼›ï¼Œï¼‰ã€‘":
            pos = s.rfind(c)
            if 200 <= pos <= 300:
                return s[:pos+1]
    return s

# ========== ä¸»æµç¨‹ ==========
def run_conv():
    if not FILE_TOC_ENT_REL.exists():
        raise FileNotFoundError(
            f"æœªæ‰¾åˆ° toc_with_entities_and_relations.jsonï¼š{FILE_TOC_ENT_REL}\n"
            f"ï¼ˆæ–‡ä»¶ååœ¨ ConvConfig.TOC_ENT_REL_NAMEï¼›è·¯å¾„å·²è‡ªåŠ¨æ‹¼æŽ¥ä¸º ExplicitKG/output ä¸‹ï¼‰"
        )

    print(f"â–¶ å¼€å§‹ Convï¼š{FILE_TOC_ENT_REL.name}")
    logger.info("å¼€å§‹è¿è¡Œ Contextual-based Convolutionï¼ˆconvï¼‰é˜¶æ®µ")
    logger.info(f"è¾“å…¥æ–‡ä»¶: {FILE_TOC_ENT_REL}")

    # 1) åŠ è½½å®žä½“ä¸Žé‚»å±…ï¼ˆä»…åŒå°èŠ‚å…±çŽ°ï¼‰
    entities = load_entities_from_toc(FILE_TOC_ENT_REL)

    # 2) ç”Ÿæˆå¢žå¼ºæè¿°
    system_prompt = build_system_prompt()
    results: Dict[str, Any] = {}

    limit = int(os.getenv("CONV_LIMIT", "0")) or None
    items = list(entities.items())[:limit] if limit else list(entities.items())
    total = len(items)
    start_ts = time.time()
    logger.info(f"å…±åŠ è½½ {total} ä¸ªå®žä½“ï¼Œå¼€å§‹è°ƒç”¨ LLM ç”Ÿæˆå¢žå¼ºæè¿°...")

    # è¿›åº¦æ¡ï¼ˆåªåœ¨ç»ˆç«¯å±•ç¤ºï¼‰
    for name, item in tqdm(items, desc="LLM ç”Ÿæˆå¢žå¼ºæè¿°", ncols=90, file=sys.stdout):
        user_prompt = build_user_prompt(item)
        content = call_llm(system_prompt, user_prompt)
        obj = safe_json_loads(content)
        upd = (obj.get("updated_description") or "").strip() or item.original or f"{name}ï¼šæš‚æ— æè¿°ã€‚"
        upd = _enforce_len_200_300(upd)
        item.updated_description = upd

        results[name] = {
            "name": name,
            "alias": item.alias,
            "type": item.type,
            "original": item.original,
            "updated_description": upd,
            "occurrences": [asdict(o) for o in item.occurrences],
            "neighbors": [asdict(nb) for nb in item.neighbors]
        }
        logger.info(f"[conv] {name} ç”ŸæˆæˆåŠŸã€‚")

    # 3) è¾“å‡ºç»“æžœ
    FILE_CONV_RESULT.parent.mkdir(parents=True, exist_ok=True)
    with FILE_CONV_RESULT.open("w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    duration = round(time.time() - start_ts, 2)
    logger.info(f"Conv é˜¶æ®µå®Œæˆï¼Œå…±å¤„ç† {len(results)} ä¸ªå®žä½“ã€‚")
    logger.info(f"è¾“å‡ºæ–‡ä»¶: {FILE_CONV_RESULT}")
    logger.info(f"æ€»è€—æ—¶: {duration} ç§’")
    print(f"âœ… Conv å®Œæˆï¼š{len(results)} ä¸ªå®žä½“ï¼Œè€—æ—¶ {duration} s  â†’  {FILE_CONV_RESULT}")
    print(f"ðŸ“ è¯¦ç»†æ—¥å¿—ï¼š{LOG_PATH}")

# ========== CLI ==========
if __name__ == "__main__":
    run_conv()
