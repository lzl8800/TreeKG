import argparse
import json
import re
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import yaml
import openai
from typing import Dict, List, Any, Optional
from tqdm import tqdm

# -------- åŸºç¡€å·¥å…· --------
def load_yaml(p: Path) -> dict:
    with p.open('r', encoding='utf-8') as f:
        return yaml.safe_load(f) or {}

def load_additional_configs(include_files: list, base_dir: Path) -> dict:
    """
    é€ä¸ªæŠŠ include çš„ yaml åˆå¹¶åˆ°ä¸€ä¸ª dict é‡Œã€‚
    include çš„è·¯å¾„ç›¸å¯¹ base_dirï¼ˆå³ config.yaml æ‰€åœ¨ç›®å½•ï¼‰ã€‚
    """
    merged = {}
    for rel in include_files or []:
        rel = str(rel)
        inc_path = Path(rel)
        if not inc_path.is_absolute():
            inc_path = (base_dir / rel).resolve()
        # å¯é€‰ï¼šå¦‚æœå†™æˆäº† "config/xxx.yaml"ï¼Œå»æ‰å¤šä½™çš„å‰ç¼€
        if not inc_path.exists() and rel.startswith("config/"):
            inc_path = (base_dir / rel.split("/", 1)[1]).resolve()
        if not inc_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°åŒ…å«æ–‡ä»¶ï¼š{inc_path}")
        merged.update(load_yaml(inc_path))
    return merged

# -------- å…ˆç¡®å®šè„šæœ¬ & é…ç½®è·¯å¾„ --------
script_dir = Path(__file__).resolve().parent
config_file = script_dir / "config" / "config.yaml"
config_dir = config_file.parent  # = ExplicitKG/config

# -------- åŠ è½½ä¸»é…ç½® + åˆå¹¶ include --------
config = load_yaml(config_file)
additional_config = load_additional_configs(config.get('include_files', []), base_dir=config_dir)
config.update(additional_config)

print("Merged config:", config)


# ===== OpenAI é…ç½® =====
openai.api_base = config['APIConfig']['API_BASE']
openai.api_key = config['APIConfig']['API_KEY']
MODEL_NAME = config['APIConfig']['MODEL_NAME']

# ===== é€Ÿç‡é™åˆ¶ï¼ˆå¯é€‰ï¼‰=====
_rate_lock = threading.Lock()
_last_ts = 0.0
_min_interval = (1.0 / config['ExtractionConfig']['RATE_LIMIT_QPS']) if config['ExtractionConfig']['RATE_LIMIT_QPS'] > 0 else 0.0

def _rate_limit_block():
    """ç®€å•å…¨å±€é™é€Ÿï¼šä¿è¯ä¸¤æ¬¡è¯·æ±‚é—´éš” >= 1/QPS"""
    if _min_interval <= 0:
        return
    global _last_ts
    with _rate_lock:
        now = time.time()
        delta = now - _last_ts
        if delta < _min_interval:
            time.sleep(_min_interval - delta)
        _last_ts = time.time()

# ===== å·¥å…·å‡½æ•° =====
def clean_text(text: str) -> str:
    if text is None:
        return ""
    text = text.strip().replace("\u3000", " ")
    text = re.sub(r"[ \t]+", " ", text)
    text = re.sub(r"\s*\n\s*", " ", text)
    text = re.sub(r"\s{2,}", " ", text)
    return text

def _strip_code_fences(s: str) -> str:
    # å…¼å®¹æ¨¡å‹å¶å°”è¾“å‡º ```json ... ```
    s = s.strip()
    if s.startswith("```"):
        s = re.sub(r"^```(?:json)?\s*", "", s, flags=re.IGNORECASE)
        s = re.sub(r"\s*```$", "", s)
    return s.strip()

def safe_json_loads(content: str) -> Dict:
    try:
        content = _strip_code_fences(content)
        return json.loads(content)
    except Exception:
        return {}

def _chat_once(prompt: str) -> str:
    _rate_limit_block()  # QPS æ§åˆ¶ï¼ˆå¯å…³ï¼‰
    if config['ExtractionConfig']['EXTRA_THROTTLE_SEC'] > 0:  # é¢å¤–å›ºå®šèŠ‚æµï¼ˆå¯å…³ï¼‰
        time.sleep(config['ExtractionConfig']['EXTRA_THROTTLE_SEC'])
    resp = openai.ChatCompletion.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}],
        temperature=config['ExtractionConfig']['TEMPERATURE'],
        timeout=config['ExtractionConfig']['REQUEST_TIMEOUT'],
    )
    text = resp["choices"][0]["message"]["content"].strip()
    # âœ… å»é™¤ <think> ... </think> çš„éƒ¨åˆ†
    text = re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL)
    return text.strip()

def chat_with_retry(prompt: str) -> str:
    last_err: Optional[Exception] = None
    for k in range(config['ExtractionConfig']['RETRY_ATTEMPTS']):
        try:
            return _chat_once(prompt)
        except Exception as e:
            last_err = e
            backoff = (config['ExtractionConfig']['RETRY_BACKOFF_BASE'] ** k)
            time.sleep(backoff)
    raise RuntimeError(f"LLM è¯·æ±‚å¤±è´¥ï¼ˆå·²é‡è¯• {config['ExtractionConfig']['RETRY_ATTEMPTS']} æ¬¡ï¼‰: {last_err}")

def call_openai_json(prompt: str) -> Dict:
    try:
        content = chat_with_retry(prompt)
        return safe_json_loads(content)
    except Exception:
        return {}

# ===== æŠ½å–é€»è¾‘ =====
def extract_entities(section_summary: str) -> List[Dict]:
    section_summary = clean_text(section_summary)
    prompt = config['ExtractionConfig']['ENTITY_PROMPT'].format(section_summary=section_summary)
    data = call_openai_json(prompt)
    ents = data.get("entities", [])
    # è½»é‡æ¸…æ´—ï¼šå»é™¤ç©ºåï¼›alias æ­£è§„åŒ–ä¸ºç©ºæ•°ç»„
    cleaned = []
    for e in ents if isinstance(ents, list) else []:
        name = (e.get("name") or "").strip()
        if not name:
            continue
        alias = e.get("alias") or []
        if isinstance(alias, str):
            alias = [alias] if alias.strip() else []
        cleaned.append({
            "name": name,
            "alias": [a for a in alias if isinstance(a, str) and a.strip()],
            "type": (e.get("type") or "").strip(),
            "raw_content": (e.get("raw_content") or "").strip(),
        })
    return cleaned

def extract_relations(section_summary: str, entities: List[Dict]) -> List[Dict]:
    section_summary = clean_text(section_summary)
    names = [e.get("name", "").strip() for e in entities if e.get("name")]
    entity_list = ", ".join([n for n in names if n])
    if not entity_list:
        return []
    prompt = config['ExtractionConfig']['RELATION_PROMPT'].format(
        section_summary=section_summary,
        entity_list=entity_list
    )
    data = call_openai_json(prompt)
    if isinstance(data, list):
        rels = data
    elif isinstance(data, dict):
        rels = data.get("relations", [])
    else:
        rels = []
    cleaned = []
    for r in rels if isinstance(rels, list) else []:
        src = (r.get("source") or "").strip()
        tgt = (r.get("target") or "").strip()
        if not src or not tgt:
            continue
        cleaned.append({
            "source": src,
            "target": tgt,
            "type": (r.get("type") or "").strip(),
            "description": (r.get("description") or "").strip(),
        })
    return cleaned


def process_one_subsection(summary: str) -> Dict:
    ents = extract_entities(summary)
    if not ents:
        return {"entities": [], "relations": []}
    rels = extract_relations(summary, ents)
    return {"entities": ents, "relations": rels}

def collect_subsections(toc: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """é€‚é… 2-4 å±‚ç›®å½•ï¼Œè‡ªåŠ¨è¯†åˆ«æœ€åº•å±‚å«æ‘˜è¦çš„èŠ‚ç‚¹ã€‚"""
    subs: List[Dict[str, Any]] = []
    for level1 in toc:  # ç¬¬1å±‚ï¼ˆå¦‚â€œç¬¬2ç«  MATLABåŸºç¡€çŸ¥è¯†â€ï¼‰
        # éå†ç¬¬2å±‚ï¼ˆlevel1çš„å­èŠ‚ç‚¹ï¼Œå¦‚â€œ2.1 æ•°æ®ç±»å‹â€ï¼‰
        for level2 in level1.get("children", []) or []:
            # æ£€æŸ¥ç¬¬2å±‚æ˜¯å¦æœ‰å­èŠ‚ç‚¹ï¼ˆåˆ¤æ–­æ˜¯å¦ä¸º2å±‚ç›®å½•ï¼‰
            if not level2.get("children"):  # æ— å­èŠ‚ç‚¹ â†’ 2å±‚ç›®å½•ï¼Œç›´æ¥æ”¶é›†level2
                if level2.get("summary"):
                    subs.append(level2)
            else:  # æœ‰å­èŠ‚ç‚¹ â†’ è‡³å°‘3å±‚ç›®å½•ï¼Œç»§ç»­éå†ç¬¬3å±‚
                for level3 in level2.get("children", []) or []:
                    # æ£€æŸ¥ç¬¬3å±‚æ˜¯å¦æœ‰å­èŠ‚ç‚¹ï¼ˆåˆ¤æ–­æ˜¯å¦ä¸º3å±‚/4å±‚ç›®å½•ï¼‰
                    if not level3.get("children"):  # æ— å­èŠ‚ç‚¹ â†’ 3å±‚ç›®å½•ï¼Œæ”¶é›†level3
                        if level3.get("summary"):
                            subs.append(level3)
                    else:  # æœ‰å­èŠ‚ç‚¹ â†’ 4å±‚ç›®å½•ï¼Œéå†å¹¶æ”¶é›†ç¬¬4å±‚
                        for level4 in level3.get("children", []) or []:
                            if level4.get("summary"):
                                subs.append(level4)
    return subs

# ===== ä¸»æµç¨‹ï¼ˆå¹¶å‘ï¼‰=====
def run(max_workers: int):
    # è·å– src/ExplicitKG ç›®å½•
    script_dir = Path(__file__).resolve().parent

    # è·å–é…ç½®æ–‡ä»¶ä¸­çš„æ–‡ä»¶å
    in_json_filename = config['ExtractionConfig']['IN_NAME']
    out_json_filename = config['ExtractionConfig']['OUT_NAME']

    # æ„å»ºè¾“å…¥å’Œè¾“å‡ºè·¯å¾„
    in_json = script_dir / "output" / in_json_filename
    out_json = script_dir / "output" / out_json_filename

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not in_json.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°è¾“å…¥ï¼š{in_json}")

    # è¯»å–è¾“å…¥æ–‡ä»¶å¹¶è¿›è¡Œå¤„ç†
    with in_json.open("r", encoding=config['ExtractionConfig']['ENCODING']) as f:
        toc: List[Dict[str, Any]] = json.load(f)

    subsections = collect_subsections(toc)
    total = len(subsections)

    if total == 0:
        # ç›´æ¥è¾“å‡ºç©ºç»“æ„æˆ–åŸç»“æ„
        with out_json.open("w", encoding=config['ExtractionConfig']['ENCODING']) as f:
            json.dump(toc, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ— éœ€æŠ½å–ï¼ˆæ²¡æœ‰æ‰¾åˆ°å«æ‘˜è¦çš„å°èŠ‚ï¼‰ã€‚å·²å†™å‡ºï¼š{out_json.resolve()}")
        return

    pbar = tqdm(total=total, desc="ğŸ” å®ä½“ä¸å…³ç³»æå–", ncols=90)

    def worker(subnode: Dict[str, Any]):
        res = process_one_subsection(subnode.get("summary", ""))
        subnode["entities"] = res["entities"]
        subnode["relations"] = res["relations"]
        pbar.update(1)

    # å¹¶å‘æ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=max_workers) as pool:
        futures = [pool.submit(worker, sub) for sub in subsections]
        for fu in as_completed(futures):
            # è§¦å‘å¼‚å¸¸ç«‹å³æŠ›å‡ºï¼Œæ–¹ä¾¿å®šä½
            fu.result()

    pbar.close()

    out_json.parent.mkdir(parents=True, exist_ok=True)
    with out_json.open("w", encoding=config['ExtractionConfig']['ENCODING']) as f:
        json.dump(toc, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… å®ä½“ä¸å…³ç³»æå–å®Œæˆï¼š{out_json.resolve()}")

def main():
    ap = argparse.ArgumentParser(description="ä»ç« èŠ‚æ‘˜è¦ä¸­å¹¶å‘æŠ½å–å®ä½“ä¸å…³ç³»")
    ap.add_argument("--workers", type=int, default=config['ExtractionConfig']['MAX_WORKERS'],
                    help="å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤è§é…ç½® EXT_MAX_WORKERSï¼‰")
    args = ap.parse_args()

    run(max_workers=args.workers)

if __name__ == "__main__":
    main()
