# -*- coding: utf-8 -*-
"""
Extraction.py
Tree-KG é˜¶æ®µäºŒÂ·æ­¥éª¤1ï¼šä»ç« èŠ‚æ‘˜è¦ä¸­æå– Physics å®ä½“ä¸å…³ç³»
- è¯»å– toc_with_summaries.jsonï¼ˆå¯åœ¨ config/extraction.py ä¸­é‡å‘½åï¼‰
- å¹¶å‘ï¼šå¯¹æ¯ä¸ªå°èŠ‚æ‘˜è¦è°ƒç”¨ LLM æå–å®ä½“ä¸å…³ç³»ï¼ˆå®ä½“â†’å…³ç³»ä¸²è¡Œï¼ŒèŠ‚ç‚¹ä¹‹é—´å¹¶è¡Œï¼‰
- ç¨³å¥ï¼šé‡è¯• + æŒ‡æ•°é€€é¿ +ï¼ˆå¯é€‰ï¼‰QPS é™é€Ÿ + è¿›åº¦æ¡
- è¾“å‡º toc_with_entities_and_relations.jsonï¼ˆå¯åœ¨é…ç½®ä¸­ä¿®æ”¹ï¼‰
"""

import argparse
import json
import re
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Any, Dict, List, Optional

import openai
from tqdm import tqdm

# ===== è¯»å–é…ç½® =====
try:
    from config import APIConfig
    from config.extract import ExtractionConfig
except Exception as e:
    raise RuntimeError(f"æ— æ³•å¯¼å…¥é…ç½®ï¼š{e}")

# ===== OpenAI å…¼å®¹æ¥å£ =====
openai.api_base = APIConfig.API_BASE
openai.api_key = APIConfig.API_KEY
MODEL_NAME = APIConfig.MODEL_NAME

# ===== é€Ÿç‡é™åˆ¶ï¼ˆå¯é€‰ï¼‰=====
_rate_lock = threading.Lock()
_last_ts = 0.0
_min_interval = (1.0 / ExtractionConfig.RATE_LIMIT_QPS) if ExtractionConfig.RATE_LIMIT_QPS > 0 else 0.0

def _rate_limit_block():
    """ç®€å•å…¨å±€é™é€Ÿï¼šä¿è¯ä¸¤æ¬¡è¯·æ±‚é—´éš” >= 1/QPS"""
    if _min_interval <= 0:
        return
    global _last_ts
    with _rate_lock:
        now = time.time()
        delta = now - _last_ts
        if delta < _min_interval:
            time.sleep(_min_interval - delta)
        _last_ts = time.time()

# ===== å·¥å…·å‡½æ•° =====
def clean_text(text: str) -> str:
    if text is None:
        return ""
    text = text.strip().replace("\u3000", " ")
    text = re.sub(r"[ \t]+", " ", text)
    text = re.sub(r"\s*\n\s*", " ", text)
    text = re.sub(r"\s{2,}", " ", text)
    return text

def _strip_code_fences(s: str) -> str:
    # å…¼å®¹æ¨¡å‹å¶å°”è¾“å‡º ```json ... ```
    s = s.strip()
    if s.startswith("```"):
        s = re.sub(r"^```(?:json)?\s*", "", s, flags=re.IGNORECASE)
        s = re.sub(r"\s*```$", "", s)
    return s.strip()

def safe_json_loads(content: str) -> Dict:
    try:
        content = _strip_code_fences(content)
        return json.loads(content)
    except Exception:
        return {}

def _chat_once(prompt: str) -> str:
    _rate_limit_block()                                # QPS æ§åˆ¶ï¼ˆå¯å…³ï¼‰
    if ExtractionConfig.EXTRA_THROTTLE_SEC > 0:       # é¢å¤–å›ºå®šèŠ‚æµï¼ˆå¯å…³ï¼‰
        time.sleep(ExtractionConfig.EXTRA_THROTTLE_SEC)
    resp = openai.ChatCompletion.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}],
        temperature=ExtractionConfig.TEMPERATURE,
        timeout=ExtractionConfig.REQUEST_TIMEOUT,
    )
    return resp["choices"][0]["message"]["content"].strip()

def chat_with_retry(prompt: str) -> str:
    last_err: Optional[Exception] = None
    for k in range(ExtractionConfig.RETRY_ATTEMPTS):
        try:
            return _chat_once(prompt)
        except Exception as e:
            last_err = e
            backoff = (ExtractionConfig.RETRY_BACKOFF_BASE ** k)
            time.sleep(backoff)
    raise RuntimeError(f"LLM è¯·æ±‚å¤±è´¥ï¼ˆå·²é‡è¯• {ExtractionConfig.RETRY_ATTEMPTS} æ¬¡ï¼‰: {last_err}")

def call_openai_json(prompt: str) -> Dict:
    try:
        content = chat_with_retry(prompt)
        return safe_json_loads(content)
    except Exception:
        return {}

# ===== æŠ½å–é€»è¾‘ =====
def extract_entities(section_summary: str) -> List[Dict]:
    section_summary = clean_text(section_summary)
    prompt = ExtractionConfig.ENTITY_PROMPT.format(section_summary=section_summary)
    data = call_openai_json(prompt)
    ents = data.get("entities", [])
    # è½»é‡æ¸…æ´—ï¼šå»é™¤ç©ºåï¼›alias æ­£è§„åŒ–ä¸ºç©ºæ•°ç»„
    cleaned = []
    for e in ents if isinstance(ents, list) else []:
        name = (e.get("name") or "").strip()
        if not name:
            continue
        alias = e.get("alias") or []
        if isinstance(alias, str):
            alias = [alias] if alias.strip() else []
        cleaned.append({
            "name": name,
            "alias": [a for a in alias if isinstance(a, str) and a.strip()],
            "type": (e.get("type") or "").strip(),
            "raw_content": (e.get("raw_content") or "").strip(),
        })
    return cleaned

def extract_relations(section_summary: str, entities: List[Dict]) -> List[Dict]:
    section_summary = clean_text(section_summary)
    names = [e.get("name", "").strip() for e in entities if e.get("name")]
    entity_list = ", ".join([n for n in names if n])
    if not entity_list:
        return []
    prompt = ExtractionConfig.RELATION_PROMPT.format(
        section_summary=section_summary,
        entity_list=entity_list
    )
    data = call_openai_json(prompt)
    rels = data.get("relations", [])
    cleaned = []
    for r in rels if isinstance(rels, list) else []:
        src = (r.get("source") or "").strip()
        tgt = (r.get("target") or "").strip()
        if not src or not tgt:
            continue
        cleaned.append({
            "source": src,
            "target": tgt,
            "type": (r.get("type") or "").strip(),
            "description": (r.get("description") or "").strip(),
        })
    return cleaned

def process_one_subsection(summary: str) -> Dict:
    ents = extract_entities(summary)
    if not ents:
        return {"entities": [], "relations": []}
    rels = extract_relations(summary, ents)
    return {"entities": ents, "relations": rels}

def collect_subsections(toc: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æ”¶é›† level=3 å°èŠ‚ï¼ˆsection çš„ childrenï¼‰ï¼Œå¹¶ä¸”å«æœ‰ summaryã€‚"""
    subs: List[Dict[str, Any]] = []
    for ch in toc:
        for sec in ch.get("children", []) or []:
            for sub in sec.get("children", []) or []:
                if sub.get("summary"):
                    subs.append(sub)
    return subs

# ===== ä¸»æµç¨‹ï¼ˆå¹¶å‘ï¼‰=====
def run(in_json: Path, out_json: Path, max_workers: int):
    if not in_json.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°è¾“å…¥ï¼š{in_json}")

    with in_json.open("r", encoding=ExtractionConfig.ENCODING) as f:
        toc: List[Dict[str, Any]] = json.load(f)

    subsections = collect_subsections(toc)
    total = len(subsections)

    if total == 0:
        # ç›´æ¥è¾“å‡ºç©ºç»“æ„æˆ–åŸç»“æ„
        with out_json.open("w", encoding=ExtractionConfig.ENCODING) as f:
            json.dump(toc, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ— éœ€æŠ½å–ï¼ˆæ²¡æœ‰æ‰¾åˆ°å«æ‘˜è¦çš„å°èŠ‚ï¼‰ã€‚å·²å†™å‡ºï¼š{out_json.resolve()}")
        return

    pbar = tqdm(total=total, desc="ğŸ” å®ä½“ä¸å…³ç³»æå–", ncols=90)

    def worker(subnode: Dict[str, Any]):
        res = process_one_subsection(subnode.get("summary", ""))
        subnode["entities"] = res["entities"]
        subnode["relations"] = res["relations"]
        pbar.update(1)

    # å¹¶å‘æ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=max_workers) as pool:
        futures = [pool.submit(worker, sub) for sub in subsections]
        for fu in as_completed(futures):
            # è§¦å‘å¼‚å¸¸ç«‹å³æŠ›å‡ºï¼Œæ–¹ä¾¿å®šä½
            fu.result()

    pbar.close()

    out_json.parent.mkdir(parents=True, exist_ok=True)
    with out_json.open("w", encoding=ExtractionConfig.ENCODING) as f:
        json.dump(toc, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… å®ä½“ä¸å…³ç³»æå–å®Œæˆï¼š{out_json.resolve()}")

def main():
    ap = argparse.ArgumentParser(description="ä»ç« èŠ‚æ‘˜è¦ä¸­å¹¶å‘æŠ½å–å®ä½“ä¸å…³ç³»")
    ap.add_argument("--in", dest="in_json", type=str, default=str(ExtractionConfig.IN_JSON_PATH),
                    help="è¾“å…¥ JSONï¼ˆé»˜è®¤ï¼štoc_with_summaries.jsonï¼‰")
    ap.add_argument("--out", dest="out_json", type=str, default=str(ExtractionConfig.OUT_JSON_PATH),
                    help="è¾“å‡º JSONï¼ˆé»˜è®¤ï¼štoc_with_entities_and_relations.jsonï¼‰")
    ap.add_argument("--workers", type=int, default=ExtractionConfig.MAX_WORKERS,
                    help="å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤è§é…ç½® EXT_MAX_WORKERSï¼‰")
    args = ap.parse_args()

    run(Path(args.in_json), Path(args.out_json), max_workers=args.workers)

if __name__ == "__main__":
    main()
